{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeN_Rw_kYubO",
        "outputId": "c0cef1a9-34db-4722-ee49-26ec119b296e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-3.44.3-py3-none-any.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.103.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.12)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=9e3a9c55e1c5d4d3be49a7fcbdb38b833b3855c9f11b00db7c3c4723f6635c99\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, pydub, ffmpy, bitsandbytes, websockets, semantic-version, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, huggingface-hub, httpcore, transformers, httpx, fastapi, gradio-client, gradio, accelerate\n",
            "Successfully installed accelerate-0.23.0 aiofiles-23.2.1 bitsandbytes-0.41.1 fastapi-0.103.1 ffmpy-0.3.1 gradio-3.44.3 gradio-client-0.5.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.1 orjson-3.9.7 pydub-0.25.1 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tokenizers-0.13.3 transformers-4.33.1 uvicorn-0.23.2 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers gradio bitsandbytes sentencepiece accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOn8sD-nZB1d"
      },
      "outputs": [],
      "source": [
        "!pip install hf_transfer\n",
        "!HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download --local-dir-use-symlinks False \\\n",
        "--local-dir chinese-alpaca-2-7b hfl/chinese-alpaca-2-7b --exclude *.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia-cIw5aZGrm"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jEts7uVY5st"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
        "from threading import Thread\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeiPN2DqZIyZ"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "801997e1120c404bb02ce2bb4e392af6",
            "7508a218d0a14c339204eef1fef4abfb",
            "55314e86804848cf95be4ea833396837",
            "793d13e7ad2143d3aa1e2c88ed805724",
            "1d14c06992044818b25a4ac3c0b2d5e2",
            "7f685d3b3e5b4dd792b2ddcba0f7b4dc",
            "3e71c4fe82434351a3a862f67573a885",
            "ea79f68a7b4043f6a009f5a7b9724046",
            "530748bd1cf5473583fcaacb3a5eaa23",
            "92b37b92101544339b072b09321df02e",
            "8ea6194612a041c5abd10815c27d5eeb"
          ]
        },
        "id": "cDDJOwgdZYYF",
        "outputId": "db7ef108-7bc9-40d3-d77b-35449f9cc081"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "801997e1120c404bb02ce2bb4e392af6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_model_path = '/content/chinese-alpaca-2-7b'\n",
        "tokenizer = LlamaTokenizer.from_pretrained(base_model_path, legacy=True)\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    base_model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map='auto',\n",
        "    load_in_8bit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLBoiY4ndt_J"
      },
      "outputs": [],
      "source": [
        "DEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful assistant. 你是一个乐于助人的助手。\"\"\"\n",
        "TEMPLATE_WITH_SYSTEM_PROMPT = (\n",
        "    \"[INST] <<SYS>>\\n\"\n",
        "    \"{system_prompt}\\n\"\n",
        "    \"<</SYS>>\\n\\n\"\n",
        "    \"{instruction} [/INST]\"\n",
        ")\n",
        "TEMPLATE_WITHOUT_SYSTEM_PROMPT = \"[INST] {instruction} [/INST]\"\n",
        "\n",
        "def generate_prompt(instruction, response=\"\", with_system_prompt=True, system_prompt=DEFAULT_SYSTEM_PROMPT):\n",
        "    if with_system_prompt is True:\n",
        "        prompt = TEMPLATE_WITH_SYSTEM_PROMPT.format_map({'instruction': instruction,'system_prompt': system_prompt})\n",
        "    else:\n",
        "        prompt = TEMPLATE_WITHOUT_SYSTEM_PROMPT.format_map({'instruction': instruction})\n",
        "    if len(response)>0:\n",
        "        prompt += \" \" + response\n",
        "    return prompt\n",
        "\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        stop_ids = [29, 0]\n",
        "        for stop_id in stop_ids:\n",
        "            if input_ids[0][-1] == stop_id:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class Stream(StoppingCriteria):\n",
        "    def __init__(self, callback_func=None):\n",
        "        self.callback_func = callback_func\n",
        "\n",
        "    def __call__(self, input_ids, scores) -> bool:\n",
        "        if self.callback_func is not None:\n",
        "            self.callback_func(input_ids[0])\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXY1l2HzZx6A"
      },
      "source": [
        "### predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGd0qievaTUv"
      },
      "outputs": [],
      "source": [
        "# message: current user's input\n",
        "# history: a 2D-array with [[user1, sys1], [user2, sys2], ...]\n",
        "def predict(message, history):\n",
        "    history_transformer_format = history + [[message, \"\"]]\n",
        "    stop = StopOnTokens()\n",
        "\n",
        "    # first round conversation, we paste full system + input template\n",
        "    if len(history) == 0:\n",
        "        messages = generate_prompt(message, response=\"\", with_system_prompt=True, system_prompt=DEFAULT_SYSTEM_PROMPT)\n",
        "    else:\n",
        "        # handle the first input/response\n",
        "        first_input = history[0][0]\n",
        "        first_response = history[0][1]\n",
        "        messages = generate_prompt(first_input, response=first_response, with_system_prompt=True, system_prompt=DEFAULT_SYSTEM_PROMPT)\n",
        "\n",
        "        # handle the rest\n",
        "        for hist in history[1:]:\n",
        "            cur_input = hist[0]\n",
        "            cur_response = hist[1]\n",
        "            cur_prompt = generate_prompt(cur_input, response=cur_response, with_system_prompt=False)\n",
        "            messages = messages + cur_prompt\n",
        "\n",
        "        # handle the current\n",
        "        messages = messages + generate_prompt(message, response=\"\", with_system_prompt=False)\n",
        "\n",
        "    #messages = \"\".join([\"\".join([\"\\n<human>:\"+item[0], \"\\n<bot>:\"+item[1]])  #curr_system_message +\n",
        "    #            for item in history_transformer_format])\n",
        "\n",
        "    print(message)\n",
        "    print(history)\n",
        "    print(messages)\n",
        "    print('----')\n",
        "\n",
        "    model_inputs = tokenizer([messages], return_tensors=\"pt\").to(\"cuda\")\n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n",
        "    generate_kwargs = dict(\n",
        "        model_inputs,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        top_k=40,\n",
        "        temperature=0.2,\n",
        "        num_beams=1,\n",
        "        stopping_criteria=StoppingCriteriaList([Stream(callback_func=None)])\n",
        "        )\n",
        "    # StoppingCriteriaList([stop]) #\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "\n",
        "    partial_message  = \"\"\n",
        "    for new_token in streamer:\n",
        "        if new_token != '<':\n",
        "            partial_message += new_token\n",
        "            yield partial_message\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mc3KUa1IvwHB",
        "outputId": "97dd3b0b-8975-434e-ee84-d096111fbf0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G72Y2Ua9aRre"
      },
      "source": [
        "### launch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CNIC8qPdaXLE",
        "outputId": "ee23402d-4a12-403e-d8a0-0573fd9957c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6b66f533e663af200f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6b66f533e663af200f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "你好\n",
            "[]\n",
            "[INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "你好 [/INST]\n",
            "----\n",
            "请你帮我购物\n",
            "[['你好', '你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？']]\n",
            "[INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "你好 [/INST] 你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？[INST] 请你帮我购物 [/INST]\n",
            "----\n",
            "我要买最新款iphone\n",
            "[['你好', '你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？'], ['请你帮我购物', '当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。']]\n",
            "[INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "你好 [/INST] 你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？[INST] 请你帮我购物 [/INST] 当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。[INST] 我要买最新款iphone [/INST]\n",
            "----\n",
            "我需要在官网买iphone 15 pro max\n",
            "[['你好', '你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？'], ['请你帮我购物', '当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。'], ['我要买最新款iphone', '好的，最新款的 iPhone 是 iPhone 13。以下是购买 iPhone 13 的选项：\\n\\n1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 13，选择您喜欢的颜色和存储容量。\\n\\n2. 在运营商处购买：您可以在运营商处购买 iPhone 13，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\\n\\n3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 13，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\\n\\n请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。']]\n",
            "[INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "你好 [/INST] 你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？[INST] 请你帮我购物 [/INST] 当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。[INST] 我要买最新款iphone [/INST] 好的，最新款的 iPhone 是 iPhone 13。以下是购买 iPhone 13 的选项：\n",
            "\n",
            "1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 13，选择您喜欢的颜色和存储容量。\n",
            "\n",
            "2. 在运营商处购买：您可以在运营商处购买 iPhone 13，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\n",
            "\n",
            "3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 13，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\n",
            "\n",
            "请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。[INST] 我需要在官网买iphone 15 pro max [/INST]\n",
            "----\n",
            "官网\n",
            "[['你好', '你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？'], ['请你帮我购物', '当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。'], ['我要买最新款iphone', '好的，最新款的 iPhone 是 iPhone 13。以下是购买 iPhone 13 的选项：\\n\\n1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 13，选择您喜欢的颜色和存储容量。\\n\\n2. 在运营商处购买：您可以在运营商处购买 iPhone 13，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\\n\\n3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 13，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\\n\\n请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。'], ['我需要在官网买iphone 15 pro max', '好的，您可以在苹果官网上购买 iPhone 15 Pro Max。以下是购买 iPhone 15 Pro Max 的选项：\\n\\n1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 15 Pro Max，选择您喜欢的颜色和存储容量。\\n\\n2. 在运营商处购买：您可以在运营商处购买 iPhone 15 Pro Max，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\\n\\n3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 15 Pro Max，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\\n\\n请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。']]\n",
            "[INST] <<SYS>>\n",
            "You are a helpful assistant. 你是一个乐于助人的助手。\n",
            "<</SYS>>\n",
            "\n",
            "你好 [/INST] 你好！很高兴见到你。我是 Assistant，一个大型语言模型，由 OpenAI 训练。有什么我可以帮助你的吗？[INST] 请你帮我购物 [/INST] 当然可以！请告诉我你需要购买什么，我可以帮你搜索并提供购买选项。[INST] 我要买最新款iphone [/INST] 好的，最新款的 iPhone 是 iPhone 13。以下是购买 iPhone 13 的选项：\n",
            "\n",
            "1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 13，选择您喜欢的颜色和存储容量。\n",
            "\n",
            "2. 在运营商处购买：您可以在运营商处购买 iPhone 13，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\n",
            "\n",
            "3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 13，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\n",
            "\n",
            "请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。[INST] 我需要在官网买iphone 15 pro max [/INST] 好的，您可以在苹果官网上购买 iPhone 15 Pro Max。以下是购买 iPhone 15 Pro Max 的选项：\n",
            "\n",
            "1. 在苹果官网上购买：您可以在苹果官网上购买 iPhone 15 Pro Max，选择您喜欢的颜色和存储容量。\n",
            "\n",
            "2. 在运营商处购买：您可以在运营商处购买 iPhone 15 Pro Max，例如 AT&T、Verizon、T-Mobile 或 Sprint。这些运营商通常会提供一些优惠和折扣。\n",
            "\n",
            "3. 在第三方零售商处购买：您可以在第三方零售商处购买 iPhone 15 Pro Max，例如 Best Buy、Amazon 或 Walmart。这些零售商通常会提供一些优惠和折扣。\n",
            "\n",
            "请告诉我您更倾向于哪种购买方式，我可以为您提供更多信息。[INST] 官网 [/INST]\n",
            "----\n",
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "gr.ChatInterface(predict).queue().launch(share=True, debug=True)\n",
        "#gr.ChatInterface(predict).queue().launch(share=False, inbrowser=True, server_name='0.0.0.0', server_port=8765)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d14c06992044818b25a4ac3c0b2d5e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e71c4fe82434351a3a862f67573a885": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "530748bd1cf5473583fcaacb3a5eaa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55314e86804848cf95be4ea833396837": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea79f68a7b4043f6a009f5a7b9724046",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_530748bd1cf5473583fcaacb3a5eaa23",
            "value": 2
          }
        },
        "7508a218d0a14c339204eef1fef4abfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f685d3b3e5b4dd792b2ddcba0f7b4dc",
            "placeholder": "​",
            "style": "IPY_MODEL_3e71c4fe82434351a3a862f67573a885",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "793d13e7ad2143d3aa1e2c88ed805724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92b37b92101544339b072b09321df02e",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea6194612a041c5abd10815c27d5eeb",
            "value": " 2/2 [00:12&lt;00:00,  5.67s/it]"
          }
        },
        "7f685d3b3e5b4dd792b2ddcba0f7b4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801997e1120c404bb02ce2bb4e392af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7508a218d0a14c339204eef1fef4abfb",
              "IPY_MODEL_55314e86804848cf95be4ea833396837",
              "IPY_MODEL_793d13e7ad2143d3aa1e2c88ed805724"
            ],
            "layout": "IPY_MODEL_1d14c06992044818b25a4ac3c0b2d5e2"
          }
        },
        "8ea6194612a041c5abd10815c27d5eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92b37b92101544339b072b09321df02e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea79f68a7b4043f6a009f5a7b9724046": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
